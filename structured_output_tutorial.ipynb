{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Build a Stock Sentiment Analysis Program Using FREE LLMs with LangChain and Pydantic"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Table of Contents  \n",
    "1. Introduction  \n",
    "2. Setup and Dependencies  \n",
    "3. Defining the Data Models  \n",
    "4. Setting Up the Chat Model  \n",
    "5. Creating the Prompt Template  \n",
    "6. Processing Chain  \n",
    "7. Example Analysis  "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Introduction <a name=\"introduction\"></a>\n",
    "Sentiment analysis is a powerful tool in financial markets, helping investors understand market sentiment towards specific companies. This notebook uses LangChain with Structured Output to analyze news articles and extract sentiment information about mentioned companies."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "![Overview Diagram](supplementals/overview_diagram.png)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Setup and Dependencies <a name=\"setup\"></a>\n",
    "First, let's ensure we have all necessary dependencies installed."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Uncomment to install packages\n",
    "# !pip install langchain-openai langchain pydantic"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now, let's import the required libraries."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain_openai import ChatOpenAI\n",
    "from langchain.prompts import ChatPromptTemplate\n",
    "from pydantic import BaseModel, Field, field_validator\n",
    "from typing import List, Optional\n",
    "from enum import Enum\n",
    "from datetime import datetime\n",
    "import time"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Defining the Data Models <a name=\"data-models\"></a>  "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We define Pydantic models to structure our sentiment analysis output."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [],
   "source": [
    "class SentimentLabel(str, Enum):\n",
    "    POSITIVE = \"positive\"\n",
    "    MIXED = \"mixed\"\n",
    "    NEGATIVE = \"negative\"\n",
    "\n",
    "class StockSentiment(BaseModel):\n",
    "    company_name: str = Field(\n",
    "        ..., \n",
    "        description=\"The name of the company being analyzed, e.g., NVIDIA Corporation (NVDA).\"\n",
    "    )\n",
    "    justification: str = Field(\n",
    "        ..., \n",
    "        description=\"Detailed explanation with specific numbers from the article, supporting the sentiment classification.\"\n",
    "    )\n",
    "    sentiment: SentimentLabel = Field(\n",
    "        ..., \n",
    "        description=\"Sentiment classification based on the content analysis: positive, neutral, negative, or mixed.\"\n",
    "    )\n",
    "    confidence: float = Field(\n",
    "        ..., \n",
    "        description=\"Confidence level of the sentiment analysis, ranging from 0 to 1.\"\n",
    "    )\n",
    "\n",
    "    @field_validator(\"company_name\")\n",
    "    def validate_company_name(cls, v):\n",
    "        if not v.strip():\n",
    "            raise ValueError(\"Company name cannot be empty\")\n",
    "        if len(v) > 100:\n",
    "            raise ValueError(\"Company name must be 100 characters or fewer\")\n",
    "        return v\n",
    "\n",
    "    @field_validator(\"confidence\")\n",
    "    def validate_confidence(cls, v):\n",
    "        if not 0 <= v <= 1:\n",
    "            raise ValueError(\"Confidence must be between 0 and 1\")\n",
    "        return round(v, 2)  # Round to 2 decimal places for cleaner output\n",
    "\n",
    "    @field_validator(\"justification\")\n",
    "    def validate_justification(cls, v):\n",
    "        if not v.strip():\n",
    "            raise ValueError(\"Justification cannot be empty\")\n",
    "        if \"±\" in v or \"≈\" in v:  # Prevent approximations\n",
    "            raise ValueError(\"Use exact numbers from article, not approximations\")\n",
    "        return v\n",
    "\n",
    "class NewsSentiment(BaseModel):\n",
    "    stocks: List[StockSentiment] = Field(\n",
    "            ...,\n",
    "            example=[\n",
    "                {\n",
    "                    \"company_name\": \"NVIDIA Corporation (NVDA)\", \n",
    "                    \"sentiment\": \"positive\", \n",
    "                    \"confidence\": 0.95, \n",
    "                    \"justification\": \"Q4 revenue increased 15% to $22.1 billion driven by AI chip demand\"\n",
    "                },\n",
    "                {\n",
    "                    \"company_name\": \"Tesla, Inc. (TSLA)\", \n",
    "                    \"sentiment\": \"negative\", \n",
    "                    \"confidence\": 0.85, \n",
    "                    \"justification\": \"Vehicle deliveries dropped 8.5% to 435,000 units in Q3\"\n",
    "                }\n",
    "            ]\n",
    "        )\n",
    "    timestamp: datetime = Field(\n",
    "        default_factory=datetime.now,\n",
    "        description=\"Timestamp of the analysis in ISO format\"\n",
    "    )\n",
    "\n",
    "    @field_validator(\"stocks\")\n",
    "    def validate_stocks(cls, v):\n",
    "        if not v:\n",
    "            raise ValueError(\"Stocks list cannot be empty\")\n",
    "        return v"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Setting Up the Chat Model <a name=\"chat-model\"></a>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We initialize the ChatOpenAI model with specific configurations."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "![Models](supplementals/models.png)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- Gemini Reference: https://ai.google.dev/gemini-api/docs/openai  \n",
    "- LM Studio Reference: https://lmstudio.ai/docs/api/endpoints/openai"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [],
   "source": [
    "from config import GEMINI_API_KEY\n",
    "\n",
    "# Initialize Chat model, choose the mode, between 'gemini', 'lmstudio' and 'ollama'\n",
    "mode = 'gemini'\n",
    "\n",
    "if mode == 'lmstudio':\n",
    "    openai_api_base = \"http://localhost:1234/v1\"\n",
    "    openai_api_key = \"lm-studio\"\n",
    "    model_name = \"mistral-small-24b-instruct-2501\"\n",
    "    #bartowski/deepseek-r1-distill-qwen-14b\n",
    "    #deepseek-r1-redistill-qwen-1.5b-v1.0\n",
    "    #bartowski/deepseek-r1-distill-qwen-14b\n",
    "    #bartowski/deepseek-r1-distill-qwen-32b@iq2_s\n",
    "    #llama-3.1-tulu-3-8b\n",
    "    #selene-1-mini-llama-3.1-8b\n",
    "    #unsloth/phi-4\n",
    "elif mode == 'ollama':\n",
    "    openai_api_base = \"http://localhost:11434/v1\"\n",
    "    openai_api_key = \"ollama\"\n",
    "    model_name = \"deepseek-r1:14b\"\n",
    "elif mode == 'gemini':\n",
    "    openai_api_base=\"https://generativelanguage.googleapis.com/v1beta/openai/\"\n",
    "    openai_api_key = GEMINI_API_KEY\n",
    "    model_name = \"gemini-2.0-flash-exp\"\n",
    "\n",
    "model = ChatOpenAI(\n",
    "    model_name=model_name,\n",
    "    openai_api_base=openai_api_base,\n",
    "    openai_api_key=openai_api_key,\n",
    "    temperature=0 # Set temperature to 0 for deterministic output\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Add structured output capability\n",
    "structured_llm = model.with_structured_output(NewsSentiment)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Creating the Prompt Template <a name=\"prompt-template\"></a>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We define a detailed system prompt and a user prompt template."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create prompt template with detailed system message\n",
    "system_prompt = \"\"\"You are a senior financial analyst with expertise in news sentiment analysis. \n",
    "When analyzing articles, follow these guidelines:\n",
    "\n",
    "1. Identify all publicly traded companies mentioned in the text\n",
    "2. For each company, determine market sentiment based on:\n",
    "   - Explicit statements about financial performance (include exact figures/percentages)\n",
    "   - Strategic developments (mergers, partnerships, innovations)\n",
    "   - Regulatory/legal implications\n",
    "   - Market reactions (stock movements, analyst ratings)\n",
    "\n",
    "For each sentiment determination:\n",
    "- Include SPECIFIC NUMERICAL DATA from the article when available (revenue figures, percentage changes, booking numbers)\n",
    "- State QUANTIFIED IMPACTS (\"9% revenue growth\" not just \"revenue growth\")\n",
    "- Mention EXACT TIME REFERENCES (\"Q4 2023\" not just \"recently\")\n",
    "- Use PRECISE METRICS from the text ($27.35 billion, 6% stock increase)\n",
    "\n",
    "Maintain strict requirements:\n",
    "- Confidence scores must reflect article evidence strength\n",
    "- Never invent information not explicitly stated\n",
    "- Use exact company names with ticker symbols\n",
    "- Prioritize recent information when multiple data points exist\"\"\"\n",
    "\n",
    "\n",
    "user_prompt =   \"\"\" \n",
    "                    The current date is {current_date}, \n",
    "                    analyze the following article and provide sentiment analysis for each publicly traded company \n",
    "                    mentioned in the text below:\n",
    "                    {article}\n",
    "                \"\"\"\n",
    "\n",
    "prompt = ChatPromptTemplate.from_messages([\n",
    "    (\"system\", system_prompt),\n",
    "    (\"human\", user_prompt)\n",
    "])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Processing Chain <a name=\"processing-chain\"></a>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We create a processing chain that combines the prompt and the structured output model."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create processing chain\n",
    "chain = prompt | structured_llm"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Example Analysis <a name=\"example-analysis\"></a>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Let's analyze a sample news article."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "article:\n",
      "darioamodei.com /on-deepseek-and-export-controls Dario Amodei — On DeepSeek and Export Controls\n",
      "Dario Amodei25-31 minutes On DeepSeek and Export Controls January 2025  A few weeks ago I made the\n",
      "case for stronger US export controls on chips to China. Since then DeepSeek, a Chinese AI company,\n",
      "has managed to — at least in some respects — come close to the performance of US frontier AI models\n",
      "at lower cost.  Here, I won't focus on whether DeepSeek is or isn't a threat to US AI companies like\n",
      "Anthropic (although I do believe many of the claims about their threat to US AI leadership are\n",
      "greatly overstated)1. Instead, I'll focus on whether DeepSeek's releases undermine the case for\n",
      "those export control policies on chips. I don't think they do. In fact, I think they make export\n",
      "control policies even more existentially important than they were a week ago2.  Export controls\n",
      "serve a vital purpose: keeping democratic nations at the forefront of AI development. To be clear,\n",
      "they’re not a way to duck the competition between the US and China. In the end, AI companies in the\n",
      "US and other democracies must have better models than those in China if we want to prevail. But we (see more in the full article)\n"
     ]
    }
   ],
   "source": [
    "import textwrap\n",
    "\n",
    "# Example usage: load article content from file\n",
    "with open('content.txt', 'r', encoding='utf-8') as file:\n",
    "    article = file.read()\n",
    "\n",
    "wrapped_justification = textwrap.fill(article, width=100)  # Adjust width as needed\n",
    "\n",
    "# Split into lines and limit to first N rows (e.g., 5)\n",
    "lines = wrapped_justification.split('\\n')\n",
    "limited_output = '\\n'.join(lines[:12])  # Change 5 to however many lines you want\n",
    "\n",
    "print(f\"article:\\n{limited_output} (see more in the full article)\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Done!                                                                           \n",
      "\n",
      "Model Used: gemini-2.0-flash-exp\n",
      "Analysis timestamp: 2025-01-31 00:00:00+00:00\n",
      "Time taken to process the article: 3.54 seconds\n",
      "**************************************************\n",
      "Company: Nvidia (NVDA)\n",
      "Sentiment: mixed\n",
      "Confidence: 85%\n",
      "Justification: Nvidia's stock price decreased by approximately 17% following the release of DeepSeek's R1 model.\n",
      "However, the author argues that this reaction is 'baffling' and that the DeepSeek release is not bad\n",
      "for Nvidia. The article mentions that DeepSeek is reported to have 50,000 Hopper generation chips,\n",
      "which cost around $1 billion, suggesting continued demand for Nvidia's products. The author also\n",
      "notes that DeepSeek's advances are 'fully export control compliant' according to Nvidia.\n",
      "\n",
      "**************************************************\n",
      "Company: Anthropic\n",
      "Sentiment: positive\n",
      "Confidence: 90%\n",
      "Justification: The article highlights that Anthropic's Claude 3.5 Sonnet model remains notably ahead of DeepSeek's\n",
      "models in many internal and external evaluations, particularly in real-world coding. It also\n",
      "mentions that Claude 3.5 Sonnet was trained for a few $10 millions, and that it was not trained\n",
      "using a larger or more expensive model. The author also notes that Claude is extremely good at\n",
      "coding and at having a well-designed style of interaction with people.\n",
      "\n"
     ]
    }
   ],
   "source": [
    "import textwrap\n",
    "from loader import Loader  # Import the Loader class\n",
    "\n",
    "# Update example usage with current date\n",
    "current_date = datetime.now().strftime(\"%Y-%m-%d\")\n",
    "\n",
    "# Start the timer\n",
    "start_time = time.time()\n",
    "\n",
    "with Loader(\"Processing article...\"):\n",
    "    # Replace this line with your actual code\n",
    "    result = chain.invoke({\"article\": article, \"current_date\": current_date})\n",
    "print()\n",
    "\n",
    "# Calculate the elapsed time\n",
    "elapsed_time = time.time() - start_time\n",
    "\n",
    "print(f\"Model Used: {model_name}\")\n",
    "print(f\"Analysis timestamp: {result.timestamp}\")\n",
    "print(f\"Time taken to process the article: {elapsed_time:.2f} seconds\")\n",
    "\n",
    "\n",
    "for stock in result.stocks:\n",
    "    print(\"**************************************************\")\n",
    "    print(f\"Company: {stock.company_name}\")\n",
    "    print(f\"Sentiment: {stock.sentiment.value}\")\n",
    "    print(f\"Confidence: {stock.confidence:.0%}\")\n",
    "    wrapped_justification = textwrap.fill(stock.justification, width=100)  # Adjust width as needed\n",
    "    print(f\"Justification: {wrapped_justification}\")\n",
    "    print()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "llm_env",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
