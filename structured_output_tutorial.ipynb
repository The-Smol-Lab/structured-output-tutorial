{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Build a Stock Sentiment Analysis Program Using FREE LLMs with LangChain and Pydantic (Github Repo: [Link](https://github.com/krittaprot/structured-output-tutorial))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Table of Contents  \n",
    "1. Introduction  \n",
    "2. Setup and Dependencies  \n",
    "3. Defining the Data Models  \n",
    "4. Setting Up the Chat Model  \n",
    "5. Creating the Prompt Template  \n",
    "6. Processing Chain  \n",
    "7. Example Analysis  "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Introduction <a name=\"introduction\"></a>\n",
    "Sentiment analysis is a powerful tool in financial markets, helping investors understand market sentiment towards specific companies. This notebook uses LangChain with Structured Output to analyze news articles and extract sentiment information about mentioned companies."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "![Overview Diagram](supplementals/overview_diagram.png)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Setup and Dependencies <a name=\"setup\"></a>\n",
    "First, let's ensure we have all necessary dependencies installed."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Uncomment to install packages\n",
    "# !pip install langchain-openai langchain pydantic"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now, let's import the required libraries."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain_openai import ChatOpenAI\n",
    "from langchain.prompts import ChatPromptTemplate\n",
    "from pydantic import BaseModel, Field, field_validator\n",
    "from typing import List, Optional\n",
    "from enum import Enum\n",
    "from datetime import datetime\n",
    "import time"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Defining the Data Models <a name=\"data-models\"></a>  "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We define Pydantic models to structure our sentiment analysis output."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define an enumeration for sentiment labels\n",
    "class SentimentLabel(str, Enum):\n",
    "    POSITIVE = \"positive\"  # Positive sentiment\n",
    "    MIXED = \"mixed\"        # Mixed sentiment\n",
    "    NEGATIVE = \"negative\"  # Negative sentiment\n",
    "\n",
    "# Define a Pydantic model for stock sentiment analysis\n",
    "class StockSentiment(BaseModel):\n",
    "    company_name: str = Field(..., description=\"The name of the company being analyzed, e.g., NVIDIA Corporation (NVDA).\")\n",
    "    justification: str = Field(..., description=\"Detailed explanation with specific numbers from the article, supporting the sentiment classification.\")\n",
    "    sentiment: SentimentLabel = Field(..., description=\"Sentiment classification based on the content analysis: positive, neutral, negative, or mixed.\")\n",
    "    confidence: float = Field(..., description=\"Confidence level of the sentiment analysis, ranging from 0 to 1.\")\n",
    "\n",
    "    # Validator to ensure company_name is not empty and within 100 characters\n",
    "    @field_validator(\"company_name\")\n",
    "    def validate_company_name(cls, v):\n",
    "        if not v.strip():\n",
    "            raise ValueError(\"Company name cannot be empty\")\n",
    "        if len(v) > 100:\n",
    "            raise ValueError(\"Company name must be ≤ 100 characters\")\n",
    "        return v\n",
    "\n",
    "    # Validator to normalize confidence values (convert percentages to decimals)\n",
    "    @field_validator(\"confidence\")\n",
    "    def normalize_confidence(cls, v: float) -> float:\n",
    "        if isinstance(v, (int, float)) and v > 1:\n",
    "            v /= 100\n",
    "        return round(v, 2)\n",
    "\n",
    "    # Validator to ensure justification is not empty and does not contain approximations\n",
    "    @field_validator(\"justification\")\n",
    "    def validate_justification(cls, v):\n",
    "        if not v.strip():\n",
    "            raise ValueError(\"Justification cannot be empty\")\n",
    "        if \"±\" in v or \"≈\" in v:  # Prevent approximations\n",
    "            raise ValueError(\"Use exact numbers from article, not approximations\")\n",
    "        return v\n",
    "\n",
    "# Define a Pydantic model for news sentiment analysis\n",
    "class NewsSentiment(BaseModel):\n",
    "    stocks: List[StockSentiment] = Field(\n",
    "        ...,\n",
    "        example=[\n",
    "            {\n",
    "                \"company_name\": \"NVIDIA Corporation (NVDA)\", \n",
    "                \"sentiment\": \"positive\", \n",
    "                \"confidence\": 0.95, \n",
    "                \"justification\": \"Q4 revenue increased 15% to $22.1 billion driven by AI chip demand\"\n",
    "            },\n",
    "            {\n",
    "                \"company_name\": \"Tesla, Inc. (TSLA)\", \n",
    "                \"sentiment\": \"negative\", \n",
    "                \"confidence\": 0.85, \n",
    "                \"justification\": \"Vehicle deliveries dropped 8.5% to 435,000 units in Q3\"\n",
    "            }\n",
    "        ]\n",
    "    )\n",
    "    timestamp: datetime = Field(\n",
    "        default_factory=datetime.now,\n",
    "        description=\"Timestamp of the analysis in ISO format\"\n",
    "    )\n",
    "\n",
    "    # Validator to ensure stocks list is not empty\n",
    "    @field_validator(\"stocks\")\n",
    "    def validate_stocks(cls, v):\n",
    "        if not v:\n",
    "            raise ValueError(\"Stocks list cannot be empty\")\n",
    "        return v"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Setting Up the Chat Model <a name=\"chat-model\"></a>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We initialize the ChatOpenAI model with specific configurations."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "![Models](supplementals\\free_models.png)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- Gemini Reference: https://ai.google.dev/gemini-api/docs/openai  \n",
    "- LM Studio Reference: https://lmstudio.ai/docs/api/endpoints/openai\n",
    "\n",
    "Find more models at: https://lmstudio.ai/models or https://ollama.com/library"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Current rate limits for gemini 2.0 flash is:\n",
    "- 10 RPM (requests per minute)\n",
    "- 4 million TPM\n",
    "- 1,500 RPD (requests per day)\n",
    "\n",
    "Ref: [Gemini 2.0 Flash Official API Doc](https://ai.google.dev/gemini-api/docs/models/gemini#gemini-2.0-flash)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "from config import GEMINI_API_KEY\n",
    "\n",
    "# Initialize Chat model, choose the mode, between 'gemini', 'lmstudio' and 'ollama'\n",
    "mode = 'gemini'\n",
    "\n",
    "if mode == 'lmstudio':\n",
    "    openai_api_base = \"http://localhost:1234/v1\"\n",
    "    openai_api_key = \"lm-studio\"\n",
    "    model_name = \"qwen2.5-72b-instruct\"\n",
    "    #model_name = \"mistral-small-24b-instruct-2501\"\n",
    "    #model_name = \"deepseek-r1-distill-llama-8b\"\n",
    "    #bartowski/deepseek-r1-distill-qwen-14b\n",
    "    #deepseek-r1-redistill-qwen-1.5b-v1.0\n",
    "    #bartowski/deepseek-r1-distill-qwen-14b\n",
    "    #llama-3.1-tulu-3-8b\n",
    "    #selene-1-mini-llama-3.1-8b\n",
    "    #unsloth/phi-4\n",
    "elif mode == 'ollama':\n",
    "    openai_api_base = \"http://localhost:11434/v1\"\n",
    "    openai_api_key = \"ollama\"\n",
    "    model_name = \"deepseek-r1:14b\"\n",
    "elif mode == 'gemini':\n",
    "    openai_api_base=\"https://generativelanguage.googleapis.com/v1beta/openai/\"\n",
    "    openai_api_key = GEMINI_API_KEY\n",
    "    model_name = \"gemini-2.0-flash-exp\"\n",
    "\n",
    "model = ChatOpenAI(\n",
    "    model_name=model_name,\n",
    "    openai_api_base=openai_api_base,\n",
    "    openai_api_key=openai_api_key,\n",
    "    temperature=0 # Set temperature to 0 for deterministic output\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Add structured output capability\n",
    "structured_llm = model.with_structured_output(NewsSentiment)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Creating the Prompt Template <a name=\"prompt-template\"></a>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We define a detailed system prompt and a user prompt template."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create prompt template with detailed system message\n",
    "system_prompt = \"\"\"You are a senior financial analyst with expertise in news sentiment analysis. \n",
    "When analyzing articles, follow these guidelines:\n",
    "\n",
    "1. Identify all publicly traded companies mentioned in the text\n",
    "2. For each company, determine market sentiment based on:\n",
    "   - Explicit statements about financial performance (include exact figures/percentages)\n",
    "   - Strategic developments (mergers, partnerships, innovations)\n",
    "   - Regulatory/legal implications\n",
    "   - Market reactions (stock movements, analyst ratings)\n",
    "\n",
    "For each sentiment determination:\n",
    "- Include SPECIFIC NUMERICAL DATA from the article when available (revenue figures, percentage changes, booking numbers)\n",
    "- State QUANTIFIED IMPACTS (\"9% revenue growth\" not just \"revenue growth\")\n",
    "- Mention EXACT TIME REFERENCES (\"Q4 2023\" not just \"recently\")\n",
    "- Use PRECISE METRICS from the text ($27.35 billion, 6% stock increase)\n",
    "\n",
    "Maintain strict requirements:\n",
    "- Confidence scores must reflect article evidence strength\n",
    "- Never invent information not explicitly stated\n",
    "- Use exact company names with ticker symbols\n",
    "- Prioritize recent information when multiple data points exist\"\"\"\n",
    "\n",
    "\n",
    "user_prompt =   \"\"\" \n",
    "                    The current date is {current_date}, \n",
    "                    analyze the following article and provide sentiment analysis for each publicly traded company \n",
    "                    mentioned in the text below:\n",
    "                    {article}\n",
    "                \"\"\"\n",
    "\n",
    "prompt = ChatPromptTemplate.from_messages([\n",
    "    (\"system\", system_prompt),\n",
    "    (\"human\", user_prompt)\n",
    "])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Processing Chain <a name=\"processing-chain\"></a>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We create a processing chain that combines the prompt and the structured output model."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create processing chain\n",
    "chain = prompt | structured_llm"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Example Analysis <a name=\"example-analysis\"></a>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Let's analyze a sample news article."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "article:\n",
      "www.usatoday.com /story/money/investing/2025/02/07/nvidia-worst-case-scenario-stock/78016524007/\n",
      "Here's the worst case scenario for Nvidia stock 5-7 minutes 2/8/2025 The AI industry was rocked in\n",
      "recent days with the release of an open source AI model from Chinese start-up DeepSeek that can\n",
      "compete with the best AI models from U.S. companies despite purportedly costing just $6 million to\n",
      "train. While it's possible the claims about costs are exaggerated or flat-out untrue, the DeepSeek\n",
      "model appears to be the real deal.  While cheap, powerful AI models are a great thing for companies\n",
      "looking to deploy AI, it's potentially terrible news for Nvidia (NASDAQ: NVDA). The bull thesis for\n",
      "Nvidia, which dominates the market for powerful AI accelerators that are necessary to train the most\n",
      "advanced AI models, relies on the assumption that each successive generation of AI models will\n",
      "require more and more computational horsepower to train and run.  DeepSeek's breakthrough raises\n",
      "some serious questions. This uncertainty led to an epic plunge for Nvidia stock on Monday that wiped\n",
      "out hundreds of billions of dollars in market value.  Another shoe still must drop A cheap AI model (see more in the full article)\n"
     ]
    }
   ],
   "source": [
    "import textwrap\n",
    "\n",
    "# Example usage: load article content from file\n",
    "with open('content.txt', 'r', encoding='utf-8') as file:\n",
    "    article = file.read()\n",
    "\n",
    "wrapped_justification = textwrap.fill(article, width=100)  # Adjust width as needed\n",
    "\n",
    "# Split into lines and limit to first N rows (e.g., 5)\n",
    "lines = wrapped_justification.split('\\n')\n",
    "limited_output = '\\n'.join(lines[:12])  # Change 5 to however many lines you want\n",
    "\n",
    "print(f\"article:\\n{limited_output} (see more in the full article)\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Done!                                                                           \n",
      "\n",
      "Model Used: gemini-2.0-flash-exp\n",
      "Analysis timestamp: 2025-02-09 00:00:00\n",
      "Time taken to process the article: 3.10 seconds\n",
      "**************************************************\n",
      "Company: Nvidia (NASDAQ: NVDA)\n",
      "Sentiment: negative\n",
      "Confidence: 90%\n",
      "Justification: The article presents a negative outlook for Nvidia (NVDA) due to the emergence of cheaper AI models,\n",
      "such as DeepSeek's, which challenges the assumption that AI models require ever-increasing computing\n",
      "power. This uncertainty led to a significant stock plunge on Monday, wiping out hundreds of billions\n",
      "of dollars in market value. The article also mentions that Nvidia's valuation, which is over $3\n",
      "trillion, depends on the assumption that AI models will continue to improve with more computing\n",
      "resources, a notion that is being questioned. The Motley Fool suggests that there may be better\n",
      "investment opportunities than Nvidia right now.\n",
      "\n",
      "**************************************************\n",
      "Company: Intel (NASDAQ: INTC)\n",
      "Sentiment: positive\n",
      "Confidence: 70%\n",
      "Justification: Former Intel CEO Pat Gelsinger stated that \"Computing obeys the gas law. Making it dramatically\n",
      "cheaper will expand the market for it.\" The Motley Fool has positions in and recommends Intel. The\n",
      "Motley Fool recommends the following options: short February 2025 $27 calls on Intel.\n",
      "\n"
     ]
    }
   ],
   "source": [
    "import textwrap\n",
    "from loader import Loader  # Import the Loader class\n",
    "\n",
    "# Update example usage with current date\n",
    "current_date = datetime.now().strftime(\"%Y-%m-%d\")\n",
    "\n",
    "# Start the timer\n",
    "start_time = time.time()\n",
    "\n",
    "with Loader(\"Processing article...\"):\n",
    "    # Replace this line with your actual code\n",
    "    result = chain.invoke({\"article\": article, \"current_date\": current_date})\n",
    "print()\n",
    "\n",
    "# Calculate the elapsed time\n",
    "elapsed_time = time.time() - start_time\n",
    "\n",
    "print(f\"Model Used: {model_name}\")\n",
    "print(f\"Analysis timestamp: {result.timestamp}\")\n",
    "print(f\"Time taken to process the article: {elapsed_time:.2f} seconds\")\n",
    "\n",
    "\n",
    "for stock in result.stocks:\n",
    "    print(\"**************************************************\")\n",
    "    print(f\"Company: {stock.company_name}\")\n",
    "    print(f\"Sentiment: {stock.sentiment.value}\")\n",
    "    print(f\"Confidence: {stock.confidence:.0%}\")\n",
    "    wrapped_justification = textwrap.fill(stock.justification, width=100)  # Adjust width as needed\n",
    "    print(f\"Justification: {wrapped_justification}\")\n",
    "    print()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "llm_env",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
